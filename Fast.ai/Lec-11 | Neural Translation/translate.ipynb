{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate French -- English\n",
    "## *Only Questions as of now\n",
    "### Purpose: Learning Text processing + RNN (Attention + LSTM + Bi-Directional RNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('/home/devendra/projects/fastai/data/translate/fr-en')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname='europarl-v7.fr-en'\n",
    "en_fname = PATH/f'{fname}.en'\n",
    "fr_fname = PATH/f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/devendra/projects/fastai/data/translate/fr-en/europarl-v7.fr-en.en')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We only want to deal with questions as of now. Therefore applying the regex on english sentences starting with What, When etc. type questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')\n",
    "\n",
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "\n",
    "qs = [(e.group(), f.group()) for e,f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(qs, (PATH/'fr-en-qs.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = pickle.load((PATH/'fr-en-qs.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Why has no air quality test been done on this particular building since we were elected?',\n",
       "   \"Comment se fait-il qu'aucun test de qualité de l'air n'ait été réalisé dans ce bâtiment depuis notre élection ?\"),\n",
       "  ('Why has there been no Health and Safety Committee meeting since 1998?',\n",
       "   \"Comment se fait-il que le comité de santé et d'hygiène ne se soit plus réuni depuis 1998 ?\"),\n",
       "  ('Why has there been no fire drill, either in the Brussels Parliament buildings or the Strasbourg Parliament buildings?',\n",
       "   \"Comment se fait-il que nous n'ayons jamais fait d'exercice d'évacuation dans les bâtiments du Parlement de Bruxelles et de Strasbourg ?\"),\n",
       "  ('Why are there no fire instructions?',\n",
       "   \"Comment se fait-il qu'il n'y ait pas de consignes en cas d'incendie ?\"),\n",
       "  ('Why have the staircases not been improved since my accident?',\n",
       "   \"Comment se fait-il que les escaliers n'aient pas été améliorés depuis mon accident ?\")],\n",
       " 14803)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[:5], len(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_qs,fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Argument 'en' as the default tokenizer is English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Successfully Tokenized out French and English Parallel sentence-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['why',\n",
       "  'has',\n",
       "  'no',\n",
       "  'air',\n",
       "  'quality',\n",
       "  'test',\n",
       "  'been',\n",
       "  'done',\n",
       "  'on',\n",
       "  'this',\n",
       "  'particular',\n",
       "  'building',\n",
       "  'since',\n",
       "  'we',\n",
       "  'were',\n",
       "  'elected',\n",
       "  '?'],\n",
       " ['comment',\n",
       "  'se',\n",
       "  'fait',\n",
       "  '-',\n",
       "  'il',\n",
       "  \"qu'\",\n",
       "  'aucun',\n",
       "  'test',\n",
       "  'de',\n",
       "  'qualité',\n",
       "  'de',\n",
       "  \"l'\",\n",
       "  'air',\n",
       "  \"n'\",\n",
       "  'ait',\n",
       "  'été',\n",
       "  'réalisé',\n",
       "  'dans',\n",
       "  'ce',\n",
       "  'bâtiment',\n",
       "  'depuis',\n",
       "  'notre',\n",
       "  'élection',\n",
       "  '?'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tok[0], fr_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.0, 35.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(o) for o in en_tok], 90), np.percentile([len(o) for o in fr_tok], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.array([len(o)<30 for o in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\n",
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = load_ids('en')\n",
    "fr_ids,fr_itos,fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['comment',\n",
       "  'se',\n",
       "  'fait',\n",
       "  '-',\n",
       "  'il',\n",
       "  \"qu'\",\n",
       "  'aucun',\n",
       "  'test',\n",
       "  'de',\n",
       "  'qualité',\n",
       "  'de',\n",
       "  \"l'\",\n",
       "  'air',\n",
       "  \"n'\",\n",
       "  'ait',\n",
       "  'été',\n",
       "  'réalisé',\n",
       "  'dans',\n",
       "  'ce',\n",
       "  'bâtiment',\n",
       "  'depuis',\n",
       "  'notre',\n",
       "  'élection',\n",
       "  '?',\n",
       "  '_eos_'],\n",
       " 8556,\n",
       " 11222)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_itos[o] for o in fr_ids[0]], len(en_itos), len(fr_itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far, So Good...Managed to save the tokenized clean data and avoided future redundant pre-processing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the fastText library from facebook research\n",
    "### Can be installed from -> https://github.com/facebookresearch/fastText.git\n",
    "### Neat Trick : Instead of downloading/cloning then running the script, this can be used:\n",
    "\n",
    "\n",
    "### ! pip install git+https://github.com/facebookresearch/fastText.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use the fastText library, you'll need to download fasttext word vectors for your language (download the 'bin plus text' ones).\n",
    "### Link For all languages : [https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md]\n",
    "### English : bin+text[https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip]\n",
    "### French: bin+text[https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.zip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs = ft.load_model(str((PATH/'wiki.en/wiki.en.bin')))\n",
    "fr_vecs = ft.load_model(str((PATH/'wiki.fr/wiki.fr.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl','wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = get_vecs('en', en_vecs)\n",
    "fr_vecd = get_vecs('fr', fr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "fr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_fr_vec = len(fr_vecd[','])\n",
    "dim_en_vec,dim_fr_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0075652334, 0.29283327)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 33)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 99))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 97))\n",
    "enlen_90,frlen_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids_tr = np.array([o[:enlen_90] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:frlen_90] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11713, 1325)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr))>0.1\n",
    "en_trn,fr_trn = en_ids_tr[trn_keep],fr_ids_tr[trn_keep]\n",
    "en_val,fr_val = en_ids_tr[~trn_keep],fr_ids_tr[~trn_keep]\n",
    "len(en_trn),len(en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = Seq2SeqDataset(fr_trn,en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val,en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 6), (21, 13), (25, 14), (10, 4), (19, 11)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh,nl = 256,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531 [\"qu'\", \"d'\", 'l’', '-ce', \"n'\"]\n",
      "251 ['t_up', '’s', ':', '000', '1']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d9474e0c5a4f618088dcd24c6afca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 61/94 [00:13<00:07,  4.62it/s, loss=37]  "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7f9ab23045462ab3d5a92b9688c069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      6.43034    5.86213   \n",
      "    1      5.793968   5.0093                              \n",
      "    2      5.055109   4.788122                            \n",
      "    3      4.870533   4.686172                            \n",
      "    4      4.262737   4.31536                             \n",
      "    5      4.073639   4.111049                            \n",
      "    6      3.8919     4.066538                            \n",
      "    7      3.645197   3.936129                            \n",
      "    8      3.571479   3.877398                            \n",
      "    9      3.409587   3.752161                            \n",
      "    10     3.430935   3.701442                            \n",
      "    11     3.143175   3.685953                            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.68595])]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quelle est la situation concernant la réforme judiciaire et les mesures anticorruption qui sont encore nécessaires ? _eos_\n",
      "what is the situation when it comes to the judicial reform and anti - corruption measures that are still needed ? _eos_\n",
      "what is the situation the the the the the the the the the the ? ? ? _eos_ _eos_\n",
      "\n",
      "quelle aurait été l' alternative si l' on n' avait pas entériné , pour l' essentiel , le pacte de confiance sur l' emploi ? _eos_\n",
      "what might the alternative have been if the confidence pact for employment had not , in essence , been ratified ? _eos_\n",
      "what would would the the the the the the the the the the the the the the the the the ? ? ? _eos_ _eos_ _eos_\n",
      "\n",
      "quelle politique l' union , et non pas les états membres , doit - elle poursuivre à moyen et à long terme ? _eos_\n",
      "what policy should the union - and not the member states - pursue in the medium and long - term ? _eos_\n",
      "what policy the the , , , , , , , , the the the the the the ? ? ? _eos_ _eos_\n",
      "\n",
      "quel était le pourcentage de gel volontaire lors qu' il y avait 10 % de gel et quel était - il lorsqu' il y en avait 5 % ? _eos_\n",
      "what was the voluntary set - aside when the rate was 10 % , and when it was 5 % ? _eos_\n",
      "what was was was was a a a a a a a % % % % % ? ? ? _eos_\n",
      "\n",
      "quelle action le conseil compte-t-il entreprendre sur la base des rapports prouvant que la police avait commis des abus à l' occasion d' un événement capital de l' ue ? _eos_\n",
      "what action will the council take on the basis of the reports of police misconduct at a vital eu event ? _eos_\n",
      "what action does the council take to to to the the the the the the the the the the the the ? ? ? _eos_ _eos_ _eos_\n",
      "\n",
      "quelle sera l' attitude de la présidence britannique quant à la poursuite des relations entre l' ue et t_up asean ? _eos_\n",
      "what will be the attitude of the british presidency in the continuation of relations between the eu and t_up asean ? _eos_\n",
      "what will the the the 's 's the the the the the the the the the the the the ? ? _eos_ _eos_\n",
      "\n",
      "quel est le lien entre le rapport annuel et le pourcentage inquiétant réalisé en allemagne par un parti de droite ? _eos_\n",
      "what has the annual report to do with the frightening percentages achieved by a right - wing party in germany ? _eos_\n",
      "what is the the the the the the the the the the the the the the ? ? ? _eos_\n",
      "\n",
      "que répondez - vous à ceux qui estiment qu' il y a deux poids , deux mesures , de la part de l' union européenne , face à ces deux cas ? _eos_\n",
      "what do you say to those who believe that the european union is applying double standards in these two cases ? _eos_\n",
      "what do you you the and the the the the the the the the the the the ? ? ? ? ? ? _eos_ _eos_ _eos_ _eos_\n",
      "\n",
      "quand présenterez - vous une proposition à cette assemblée qui rendra obligatoires les tests t_up esb au sein de l' union européenne ? _eos_\n",
      "when will you present the house with a proposal to prescribe t_up bse testing as compulsory in the european union ? _eos_\n",
      "when will you you to the the the the the the the the t_up t_up ? ? _eos_ _eos_\n",
      "\n",
      "pourquoi la commission ne reprendrait - elle pas notre proposition d ' étendre la possibilité du système du prix unique du livre à l ' ensemble des états membres ? _eos_\n",
      "why will the commission not take up our proposal to extend the fixed book price system to all member states ? _eos_\n",
      "why should the commission the the the the the the the the the the the the the the the the the ? ? _eos_ _eos_ _eos_ _eos_ _eos_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Target:\n",
    "## Bidirectional LSTM\n",
    "## Teacher Forcing\n",
    "## Attention Model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
